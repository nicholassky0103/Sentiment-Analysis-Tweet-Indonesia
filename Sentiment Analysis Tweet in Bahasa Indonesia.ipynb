{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b845ccb2",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Tweet in Bahasa Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17645176",
   "metadata": {},
   "source": [
    "# Import General Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e46d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas Sky\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Nicholas Sky\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Nicholas Sky\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\\n%s\" %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a64e4f",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39707475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Acara TV</th>\n",
       "      <th>Jumlah Retweet</th>\n",
       "      <th>Text Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>HitamPutihTransTV</td>\n",
       "      <td>12</td>\n",
       "      <td>Undang @N_ShaniJKT48 ke hitamputih, pemenang S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>HitamPutihTransTV</td>\n",
       "      <td>6</td>\n",
       "      <td>Selamat berbuka puasa Semoga amal ibadah hari ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>HitamPutihTransTV</td>\n",
       "      <td>9</td>\n",
       "      <td>Ada nih di trans7 hitam putih, dia dpt penghar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>HitamPutihTransTV</td>\n",
       "      <td>2</td>\n",
       "      <td>selamat ya mas @adietaufan masuk hitamputih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>HitamPutihTransTV</td>\n",
       "      <td>1</td>\n",
       "      <td>Asiknya nonton Hitam Putih Trans7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>negative</td>\n",
       "      <td>MataNajwaMetroTV</td>\n",
       "      <td>0</td>\n",
       "      <td>ini apa banget deh gw paling kesel klo orang2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>negative</td>\n",
       "      <td>MataNajwaMetroTV</td>\n",
       "      <td>0</td>\n",
       "      <td>Orang miskin semakin miskin klo sekolah melaku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>negative</td>\n",
       "      <td>MataNajwaMetroTV</td>\n",
       "      <td>0</td>\n",
       "      <td>ga boLeh emosi, cepat tua, nonton #matanajwame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>negative</td>\n",
       "      <td>MataNajwaMetroTV</td>\n",
       "      <td>0</td>\n",
       "      <td>dr penampilan saja kyk preman taunya bkin kisr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>negative</td>\n",
       "      <td>MataNajwaMetroTV</td>\n",
       "      <td>0</td>\n",
       "      <td>Jawab aja ga usah berbelit-belit. Muter2 ga je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Sentiment           Acara TV  Jumlah Retweet  \\\n",
       "0      1  positive  HitamPutihTransTV              12   \n",
       "1      2  positive  HitamPutihTransTV               6   \n",
       "2      3  positive  HitamPutihTransTV               9   \n",
       "3      4  positive  HitamPutihTransTV               2   \n",
       "4      5  positive  HitamPutihTransTV               1   \n",
       "..   ...       ...                ...             ...   \n",
       "395  396  negative   MataNajwaMetroTV               0   \n",
       "396  397  negative   MataNajwaMetroTV               0   \n",
       "397  398  negative   MataNajwaMetroTV               0   \n",
       "398  399  negative   MataNajwaMetroTV               0   \n",
       "399  400  negative   MataNajwaMetroTV               0   \n",
       "\n",
       "                                            Text Tweet  \n",
       "0    Undang @N_ShaniJKT48 ke hitamputih, pemenang S...  \n",
       "1    Selamat berbuka puasa Semoga amal ibadah hari ...  \n",
       "2    Ada nih di trans7 hitam putih, dia dpt penghar...  \n",
       "3          selamat ya mas @adietaufan masuk hitamputih  \n",
       "4                    Asiknya nonton Hitam Putih Trans7  \n",
       "..                                                 ...  \n",
       "395  ini apa banget deh gw paling kesel klo orang2 ...  \n",
       "396  Orang miskin semakin miskin klo sekolah melaku...  \n",
       "397  ga boLeh emosi, cepat tua, nonton #matanajwame...  \n",
       "398  dr penampilan saja kyk preman taunya bkin kisr...  \n",
       "399  Jawab aja ga usah berbelit-belit. Muter2 ga je...  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataset that will be used is from GitHub\n",
    "url = \"https://raw.githubusercontent.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia/master/dataset_tweet_sentimen_tayangan_tv.csv\"\n",
    "download = requests.get(url).content\n",
    "\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eeefea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Id              400 non-null    int64 \n",
      " 1   Sentiment       400 non-null    object\n",
      " 2   Acara TV        400 non-null    object\n",
      " 3   Jumlah Retweet  400 non-null    int64 \n",
      " 4   Text Tweet      400 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b31a6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40b0d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Undang @N_ShaniJKT48 ke hitamputih, pemenang S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Selamat berbuka puasa Semoga amal ibadah hari ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Ada nih di trans7 hitam putih, dia dpt penghar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>selamat ya mas @adietaufan masuk hitamputih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>Asiknya nonton Hitam Putih Trans7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>negative</td>\n",
       "      <td>ini apa banget deh gw paling kesel klo orang2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>negative</td>\n",
       "      <td>Orang miskin semakin miskin klo sekolah melaku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>negative</td>\n",
       "      <td>ga boLeh emosi, cepat tua, nonton #matanajwame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>negative</td>\n",
       "      <td>dr penampilan saja kyk preman taunya bkin kisr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>negative</td>\n",
       "      <td>Jawab aja ga usah berbelit-belit. Muter2 ga je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment                                         Text Tweet\n",
       "0    positive  Undang @N_ShaniJKT48 ke hitamputih, pemenang S...\n",
       "1    positive  Selamat berbuka puasa Semoga amal ibadah hari ...\n",
       "2    positive  Ada nih di trans7 hitam putih, dia dpt penghar...\n",
       "3    positive        selamat ya mas @adietaufan masuk hitamputih\n",
       "4    positive                  Asiknya nonton Hitam Putih Trans7\n",
       "..        ...                                                ...\n",
       "395  negative  ini apa banget deh gw paling kesel klo orang2 ...\n",
       "396  negative  Orang miskin semakin miskin klo sekolah melaku...\n",
       "397  negative  ga boLeh emosi, cepat tua, nonton #matanajwame...\n",
       "398  negative  dr penampilan saja kyk preman taunya bkin kisr...\n",
       "399  negative  Jawab aja ga usah berbelit-belit. Muter2 ga je...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop unused features\n",
    "df.drop(['Id', 'Acara TV', 'Jumlah Retweet'], axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89885993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Undang @N_ShaniJKT48 ke hitamputih, pemenang S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Selamat berbuka puasa Semoga amal ibadah hari ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ada nih di trans7 hitam putih, dia dpt penghar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>selamat ya mas @adietaufan masuk hitamputih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Asiknya nonton Hitam Putih Trans7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>ini apa banget deh gw paling kesel klo orang2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>Orang miskin semakin miskin klo sekolah melaku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>ga boLeh emosi, cepat tua, nonton #matanajwame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>dr penampilan saja kyk preman taunya bkin kisr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>Jawab aja ga usah berbelit-belit. Muter2 ga je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                         Text Tweet\n",
       "0            1  Undang @N_ShaniJKT48 ke hitamputih, pemenang S...\n",
       "1            1  Selamat berbuka puasa Semoga amal ibadah hari ...\n",
       "2            1  Ada nih di trans7 hitam putih, dia dpt penghar...\n",
       "3            1        selamat ya mas @adietaufan masuk hitamputih\n",
       "4            1                  Asiknya nonton Hitam Putih Trans7\n",
       "..         ...                                                ...\n",
       "395          0  ini apa banget deh gw paling kesel klo orang2 ...\n",
       "396          0  Orang miskin semakin miskin klo sekolah melaku...\n",
       "397          0  ga boLeh emosi, cepat tua, nonton #matanajwame...\n",
       "398          0  dr penampilan saja kyk preman taunya bkin kisr...\n",
       "399          0  Jawab aja ga usah berbelit-belit. Muter2 ga je...\n",
       "\n",
       "[400 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the sentiment values to integer\n",
    "df['Sentiment'] = df['Sentiment'].replace(['positive', 'negative'], [1, 0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6325add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Sentiment   400 non-null    int64 \n",
      " 1   Text Tweet  400 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d182be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    200\n",
       "0    200\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengecek Imbalanced Data\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522ee9f",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c054faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libary for text preprocessing\n",
    "from Sastrawi.Dictionary.ArrayDictionary import ArrayDictionary\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemover import StopWordRemover\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "#We add additional dataset that contains stopwords in Bahasa Indonesia from GitHub\n",
    "url_stopwords = \"https://raw.githubusercontent.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia/master/stopword_tweet_pilkada_DKI_2017.csv\"\n",
    "download_stopwords = requests.get(url_stopwords).content\n",
    "\n",
    "stopwords = pd.read_csv(io.StringIO(download_stopwords.decode('utf-8')), header = None)\n",
    "\n",
    "#Create function for text (data) preprocessing\n",
    "class DataPreprocessing:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "    def remove_signs(self, feature, new = None):\n",
    "        def delete_sign(tweet):\n",
    "            # Remove number in string\n",
    "            tweet = re.sub(r'[0-9]+', '', tweet)\n",
    "            # Remove tab, new line, double space and back slice\n",
    "            tweet = tweet.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\").replace('\\s+', \" \")\n",
    "            # Remove non ASCII (emoticon, chinese word, .etc)\n",
    "            tweet = tweet.encode('ascii', 'replace').decode('ascii')\n",
    "            # Remove mention, link, hashtag\n",
    "            tweet = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", tweet).split())\n",
    "            # Remove incomplete URL\n",
    "            tweet = tweet.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "            # Remove doublespace and doubletick\n",
    "            return tweet.replace('\"', \"\").replace(\"'\", \"\").replace(\"  \", \" \")\n",
    "\n",
    "        sentence = []\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            sentence.append(delete_sign(row[feature]))\n",
    "        if new:\n",
    "            self.dataframe[new] = sentence\n",
    "        else:\n",
    "            self.dataframe[feature] = sentence\n",
    "    \n",
    "    def remove_stopwords(self, feature, new = None):\n",
    "        factory = StopWordRemoverFactory()\n",
    "\n",
    "        # Add custom stopwords\n",
    "        stopword_custom =[\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', 'kalo', 'amp', 'biar', 'bikin', 'bilang', 'gak', 'ga', 'krn', 'nya', 'nih', 'sih', 'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', 'jd', 'jgn', 'sdh', 'aja', 'nyg', 'hehe', 'pen', 'nan', 'loh','&amp', 'yah']\n",
    "        stopword_custom.extend(stopwords)\n",
    "\n",
    "        # Add custom stopword to sastrawi and convert to dictionary\n",
    "        stopword_sastrawi = factory.get_stop_words() + stopword_custom\n",
    "        dictionary = ArrayDictionary(stopword_sastrawi)\n",
    "\n",
    "        # Create StopWordRemover Function and add custom stopwords list\n",
    "        stopword = StopWordRemover(dictionary)\n",
    "\n",
    "        sentence = []\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            sentence.append(stopword.remove(row[feature]))\n",
    "\n",
    "        if new:\n",
    "            self.dataframe[new] = sentence\n",
    "        else:\n",
    "            self.dataframe[feature] = sentence\n",
    "\n",
    "    def text_stemming(self, feature, new = None):\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        def stemming(tweet):\n",
    "            tweet = stemmer.stem(tweet)\n",
    "            return tweet\n",
    "        \n",
    "        sentence = []\n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            sentence.append(stemming(row[feature]))\n",
    "\n",
    "        if new:\n",
    "            self.dataframe[new] = sentence\n",
    "        else:\n",
    "            self.dataframe[feature] = sentence\n",
    "    \n",
    "    # Lazy Preprocessing\n",
    "    def text_preprocessing(self, feature, new = None):\n",
    "        if new:\n",
    "            self.remove_signs(feature, new)\n",
    "            self.remove_stopwords(new, new)\n",
    "            self.text_stemming(new, new)\n",
    "        else:\n",
    "            self.remove_signs(feature)\n",
    "            self.remove_stopwords(feature)\n",
    "            self.text_stemming(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b955d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text Tweet</th>\n",
       "      <th>Tweet Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Undang @N_ShaniJKT48 ke hitamputih, pemenang S...</td>\n",
       "      <td>undang shanijkt hitamputih menang ssk jkt haru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Selamat berbuka puasa Semoga amal ibadah hari ...</td>\n",
       "      <td>selamat buka puasa moga amal ibadah hari ni te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ada nih di trans7 hitam putih, dia dpt penghar...</td>\n",
       "      <td>ada di trans hitam putih dpt harga di norwegia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>selamat ya mas @adietaufan masuk hitamputih</td>\n",
       "      <td>selamat mas masuk hitamputih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Asiknya nonton Hitam Putih Trans7</td>\n",
       "      <td>asiknya nonton hitam putih trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>ini apa banget deh gw paling kesel klo orang2 ...</td>\n",
       "      <td>apa banget deh gw paling kesel orang debat pak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>Orang miskin semakin miskin klo sekolah melaku...</td>\n",
       "      <td>orang miskin makin miskin sekolah laku pungut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>ga boLeh emosi, cepat tua, nonton #matanajwame...</td>\n",
       "      <td>boleh emosi cepat tua nonton lihat bapak tiba ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>dr penampilan saja kyk preman taunya bkin kisr...</td>\n",
       "      <td>dr tampil kyk preman tau bkin kisruh usak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>Jawab aja ga usah berbelit-belit. Muter2 ga je...</td>\n",
       "      <td>jawab usah belit muter jelas buang waktu ga mutu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                         Text Tweet  \\\n",
       "0            1  Undang @N_ShaniJKT48 ke hitamputih, pemenang S...   \n",
       "1            1  Selamat berbuka puasa Semoga amal ibadah hari ...   \n",
       "2            1  Ada nih di trans7 hitam putih, dia dpt penghar...   \n",
       "3            1        selamat ya mas @adietaufan masuk hitamputih   \n",
       "4            1                  Asiknya nonton Hitam Putih Trans7   \n",
       "..         ...                                                ...   \n",
       "395          0  ini apa banget deh gw paling kesel klo orang2 ...   \n",
       "396          0  Orang miskin semakin miskin klo sekolah melaku...   \n",
       "397          0  ga boLeh emosi, cepat tua, nonton #matanajwame...   \n",
       "398          0  dr penampilan saja kyk preman taunya bkin kisr...   \n",
       "399          0  Jawab aja ga usah berbelit-belit. Muter2 ga je...   \n",
       "\n",
       "                                         Tweet Cleaned  \n",
       "0    undang shanijkt hitamputih menang ssk jkt haru...  \n",
       "1    selamat buka puasa moga amal ibadah hari ni te...  \n",
       "2       ada di trans hitam putih dpt harga di norwegia  \n",
       "3                         selamat mas masuk hitamputih  \n",
       "4                     asiknya nonton hitam putih trans  \n",
       "..                                                 ...  \n",
       "395  apa banget deh gw paling kesel orang debat pak...  \n",
       "396  orang miskin makin miskin sekolah laku pungut ...  \n",
       "397  boleh emosi cepat tua nonton lihat bapak tiba ...  \n",
       "398          dr tampil kyk preman tau bkin kisruh usak  \n",
       "399   jawab usah belit muter jelas buang waktu ga mutu  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the preprocessing function\n",
    "df_preprocessing = DataPreprocessing(df)\n",
    "df_preprocessing.text_preprocessing('Text Tweet', 'Tweet Cleaned')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0390749",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d528babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Tweet Cleaned'], df['Sentiment'], shuffle=True, test_size=0.2, stratify=df['Sentiment'], random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5ece7",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052cb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Count Vectorize\n",
    "count_vector = CountVectorizer(max_features=10000)\n",
    "count_vector.fit_transform(X_train)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vector = TfidfVectorizer(max_features=10000)\n",
    "tfidf_vector.fit_transform(X_train)\n",
    "\n",
    "# For this case, we will use the TF-IDF\n",
    "X_train = tfidf_vector.transform(X_train)\n",
    "X_test = tfidf_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d6669",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b247b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Init for SVM\n",
    "svm = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "def eval_classification(model, pred, xtrain, ytrain, xtest, ytest):\n",
    "    # Init List\n",
    "    fpr, tpr, thresholds = roc_curve (ytest, pred, pos_label=1) # pos_label is positive label for metric, default is 1\n",
    "    acc = \"%.4f\" % accuracy_score(ytest, pred)\n",
    "    prc = \"%.4f\" % precision_score(ytest, pred)\n",
    "    rec = \"%.4f\" % recall_score(ytest, pred)\n",
    "    f1s = \"%.4f\" % f1_score(ytest, pred)\n",
    "    aucs = \"%.4f\" % auc(fpr, tpr)\n",
    "    data = [['Accuracy', acc], ['Precision', prc], ['Recall', rec], ['F1-Score', f1s], ['AUC', aucs]]\n",
    "\n",
    "    # Create DataFrame of the metrics\n",
    "    summary = pd.DataFrame(data, columns=['Metric', 'Value'])\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98f7e1",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a52977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.7949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Value\n",
       "0   Accuracy  0.8000\n",
       "1  Precision  0.8158\n",
       "2     Recall  0.7750\n",
       "3   F1-Score  0.7949\n",
       "4        AUC  0.8000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "imp_logreg = logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "\n",
    "summary = eval_classification(imp_logreg, logreg_pred, X_train, y_train, X_test, y_test)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b42e7",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2ec4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.6538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.7391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Value\n",
       "0   Accuracy  0.7000\n",
       "1  Precision  0.6538\n",
       "2     Recall  0.8500\n",
       "3   F1-Score  0.7391\n",
       "4        AUC  0.7000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=15\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "imp_knn = knn.fit(X_train, y_train)\n",
    "knn_pred = imp_knn.predict(X_test)\n",
    "\n",
    "summary = eval_classification(imp_knn, knn_pred, X_train, y_train, X_test, y_test)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1ddad7",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "962b89a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.8101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Value\n",
       "0   Accuracy  0.8125\n",
       "1  Precision  0.8205\n",
       "2     Recall  0.8000\n",
       "3   F1-Score  0.8101\n",
       "4        AUC  0.8125"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_svm = svm.fit(X_train, y_train)\n",
    "svm_pred = imp_svm.predict(X_test)\n",
    "\n",
    "summary = eval_classification(imp_svm, svm_pred, X_train, y_train, X_test, y_test)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbdef0",
   "metadata": {},
   "source": [
    "# Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9177f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetPreprocessing:\n",
    "    def __init__(self, tweet, vector):\n",
    "        self.tweet = tweet\n",
    "        self.vector = vector\n",
    "\n",
    "    # THIS FUNCTION FOR PREPROCESSING TEXT IN DATAFRAME\n",
    "    def remove_signs(self, tweet):\n",
    "        # Remove number in string\n",
    "        tweet = re.sub(r'[0-9]+', '', tweet)\n",
    "        # Remove tab, new line, double space and back slice\n",
    "        tweet = tweet.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\").replace('\\s+', \" \")\n",
    "        # Remove non ASCII (emoticon, chinese word, .etc)\n",
    "        tweet = tweet.encode('ascii', 'replace').decode('ascii')\n",
    "        # Remove mention, link, hashtag\n",
    "        tweet = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", tweet).split())\n",
    "        # Remove incomplete URL\n",
    "        tweet = tweet.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "        # Remove doublespace and doubletick\n",
    "        return tweet.replace('\"', \"\").replace(\"'\", \"\").replace(\"  \", \" \")\n",
    "    \n",
    "    def remove_stopwords(self, tweet):\n",
    "        factory = StopWordRemoverFactory()\n",
    "\n",
    "        # You can custom stopwords list below, we will use stopword custom for remove stopword\n",
    "        stopword_custom =[\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', 'kalo', 'amp', 'biar', 'bikin', 'bilang', 'gak', 'ga', 'krn', 'nya', 'nih', 'sih', 'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', 'jd', 'jgn', 'sdh', 'aja', 'nyg', 'hehe', 'pen', 'nan', 'loh','&amp', 'yah']\n",
    "        stopword_custom.extend(stopwords)\n",
    "\n",
    "        # Add custom stopword to sastrawi and convert to dictionary\n",
    "        stopword_sastrawi = factory.get_stop_words() + stopword_custom\n",
    "        dictionary = ArrayDictionary(stopword_sastrawi)\n",
    "\n",
    "        # Create StopWordRemover Function and add custom stopwords list\n",
    "        stopword = StopWordRemover(dictionary)\n",
    "\n",
    "        tweet = stopword.remove(tweet)\n",
    "        return tweet\n",
    "\n",
    "    def text_stemming(self, tweet):\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "\n",
    "        tweet = stemmer.stem(tweet)\n",
    "        return tweet\n",
    "\n",
    "    def vectorizer(self, tweet, vector = tfidf_vector) :\n",
    "        output = vector.transform([tweet])\n",
    "        return output\n",
    "\n",
    "    # Lazy Preprocessing\n",
    "    def text_preprocessing(self):\n",
    "        proc_sign = self.remove_signs(self.tweet)\n",
    "        proc_stop = self.remove_stopwords(proc_sign)\n",
    "        proc_stem = self.text_stemming(proc_stop)\n",
    "        proc_vect = self.vectorizer(proc_stem, self.vector)\n",
    "        return proc_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c648a8",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b66552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: anjay keren om\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "comment = input(\"Comment: \")\n",
    "\n",
    "# Init Preprocessing\n",
    "process = TweetPreprocessing(comment, tfidf_vector)\n",
    "text = process.text_preprocessing()\n",
    "\n",
    "# Predicting Sentiment\n",
    "result_logreg = imp_logreg.predict(text)\n",
    "if result_logreg[0] == 0:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfad10a",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "378d6f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: lah kamu kok telat\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "comment = input(\"Comment: \")\n",
    "\n",
    "# Init Preprocessing\n",
    "process = TweetPreprocessing(comment, tfidf_vector)\n",
    "text = process.text_preprocessing()\n",
    "\n",
    "# Predicting Sentiment\n",
    "result_knn = imp_knn.predict(text)\n",
    "if result_knn[0] == 0:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211490d",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22f273f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: dasar anak kurang ajar\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "comment = input(\"Comment: \")\n",
    "\n",
    "# Init Preprocessing\n",
    "process = TweetPreprocessing(comment, tfidf_vector)\n",
    "text = process.text_preprocessing()\n",
    "\n",
    "# Predicting Sentiment\n",
    "result_svm = imp_svm.predict(text)\n",
    "if result_svm[0] == 0:\n",
    "    print('Negative')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925af4c",
   "metadata": {},
   "source": [
    "# Saving The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcd75791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_Classifier.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(imp_logreg, 'Logistic_Regression_Classifier.pkl')\n",
    "joblib.dump(imp_knn, 'KNN_Classifier.pkl')\n",
    "joblib.dump(imp_svm, 'SVM_Classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
